prompt_coco = {
    "GPT4V": "Generate detailed captions of each image involved in the following text. You should pay attention to the information in the given description. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original caption and the given description. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\nThe original caption for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given description. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_flickr = {
    "GPT4V": "Generate detailed captions of each image involved in the following text. You should pay attention to the information in the given description. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original caption and the given description. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\nThe original caption for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given description. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_okvqa = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\nThe original caption for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_vqa = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_nlvr2 = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Question>-<Answer> pair. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! You should also notice that <image0> is the left image and <image1> is the right image.\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}

prompt_stvqa = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_vcr = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_llava = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Option>-<Answer> pair. You should pay attention to the information in the <Answer> and tell me what is presented in the image instead of the reasoning process. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! Your output should also not clearly contain comparison while the information in <Qption>-<Answer> pair should be presented!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}

prompt_ivqa = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pair. You should pay attention to the information in the <Answer> and tell me what is presented in the image instead of the reasoning process. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! You should notice that there exists sequential information between images!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}

prompt_ivqa_frame = {
    "GPT4V": "I will give you the several images and the <Question>-<Answer> pair related to these images. You should decide which image or images best help answer the question based on the information provided by the <Question>-<Answer> pair. Your output should just be some numbers. Your output should strictly be some numbrs without other explanations. You should notice that the index of images are from 0 to 7!\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pair. You should pay attention to the information in the <Answer> and tell me what is presented in the image instead of the reasoning process. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! You should notice that there exists time information between images!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}

prompt_vsr = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Question>-<Answer> pair. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_iconqa = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original caption and the given Question-Answer pairs. You should pay attention to the information in the answer. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images.\n\nThe original caption for each image are as follows.\n"
}

prompt_CGD = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Question>-<Answer> pair. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! You should also notice that <image0> is the first image and <image1> is the second image.\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}

prompt_LA = {
    "GPT4V": "Generate detailed captions of each image involved in the following text according to the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}.\n========\n",
    "GPT4": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Option>-<Answer> pair. You should pay attention to the information in the <Answer> and tell me what is presented in the image instead of the reasoning process. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"! Your output should also not clearly contain comparison while the information in <Option>-<Answer> pair should be presented!\n========\nThe original <caption> for each image are as follows.\n",
    "GPT3": "Generate detailed captions of each image involved in the following text according to the original <caption> and the given <Question>-<Answer> pairs. You should pay attention to the information in the <Answer>. Your output should be in the json format, as {\"image0\":\"\", \"image1\":\"\", \"image2\":\"\"}. The number of items in json body should be the same as the number of images. Your output should also be natural as an original caption and not include words like \"answer\" or \"caption\"!\n========\nThe original <caption> for each image are as follows.\n"
}