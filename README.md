# ğŸ‘€ Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion

[**ğŸ“– arXiv**](https://arxiv.org/pdf/2402.12195.pdf) | [**ğŸ¤— Models**](coming soon)

This repo includes codes and examples for paper [Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion] (https://arxiv.org/pdf/2402.12195.pdf) 

## Installation
coming soon

## Instructions For Training and Inference
coming soon

## Example
![example](./figures/git_showcase.png)
(ğŸ± in this figure is a 6-year-old cat, his name is Alan.)

## Models
coming soon

## Reference

ğŸ“‘ If you find our project helpful to your research, please consider citing:

@article{wang2024browse,
  title={Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion},
  author={Wang, Ziyue and Chen, Chi and Zhu, Yiqi and Luo, Fuwen and Li, Peng and Yan, Ming and Zhang, Ji and Huang, Fei and Sun, Maosong and Liu, Yang},
  journal={arXiv preprint arXiv:2402.12195},
  year={2024}
}

